import streamlit as st
import torch
import os 
import pandas as pd
import plotly.express as px
from transformers import BertForSequenceClassification, BertTokenizer
from fetch_tweets import fetch_tweets  # Import function to fetch tweets
from utils import clean_tweet, load_past_tweets, save_tweets_to_csv  # Import from utils.py
from fpdf import FPDF # type: ignore
import speech_recognition as sr # type: ignore
from pydub import AudioSegment  # type: ignore
import io
import pyaudio # type: ignore
from supabase_client import supabase
from dotenv import load_dotenv



# Global list to store responses
responses = []

def save_response(feature, input_text, result):
    """Stores responses for generating a PDF."""
    responses.append({"feature": feature, "input": input_text, "result": result})

def generate_pdf():
    """Generates a PDF with all responses and provides a download button."""
    if not responses:
        st.warning("‚ö†Ô∏è No responses to generate a report!")
        return

    pdf = FPDF()
    pdf.set_auto_page_break(auto=True, margin=15)
    pdf.add_page()
    pdf.set_font("Arial", size=12)

    pdf.cell(200, 10, "Analysis Report", ln=True, align='C')
    pdf.ln(10)

    for response in responses:
        feature = response["feature"]
        input_text = response["input"]
        result = response["result"]

        pdf.set_font("Arial", style='B', size=12)
        pdf.cell(0, 10, f"Feature: {feature}", ln=True)
        pdf.ln(5)
        pdf.set_font("Arial", size=11)
        pdf.multi_cell(0, 8, f"Input: {input_text}")
        pdf.ln(3)
        pdf.set_font("Arial", style='B', size=11)
        pdf.multi_cell(0, 8, f"Result: {result}")
        pdf.ln(10)

    pdf_filename = "analysis_report.pdf"
    pdf.output(pdf_filename)

    with open(pdf_filename, "rb") as file:
        st.download_button(
            label="üì• Download Full Report",
            data=file,
            file_name=pdf_filename,
            mime="application/pdf"
        )


# Streamlit UI setup
st.set_page_config(
    page_title="GBV Detection & Analysis", 
    layout="wide", 
    page_icon="üõ°Ô∏è",
    initial_sidebar_state="expanded"
)

# Load GBV detection model (English BERT)
@st.cache_resource
def load_gbv_model():
    model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)
    state_dict = torch.load("bert_gbv_detector.pth", map_location="cpu")
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    return model

# Load Sentiment Analysis Model (mBERT)
@st.cache_resource
def load_sentiment_model():
    model = BertForSequenceClassification.from_pretrained("bert-base-multilingual-cased", num_labels=3)
    state_dict = torch.load("best_model.pth", map_location="cpu")
    model.load_state_dict(state_dict, strict=False)
    model.eval()
    return model

# Load Tokenizers
@st.cache_resource
def load_tokenizers():
    gbv_tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")  # English tokenizer
    sentiment_tokenizer = BertTokenizer.from_pretrained("bert-base-multilingual-cased")  # Multilingual tokenizer
    return gbv_tokenizer, sentiment_tokenizer

# Load models and tokenizers
gbv_model = load_gbv_model()
sentiment_model = load_sentiment_model()
gbv_tokenizer, sentiment_tokenizer = load_tokenizers()

# Define class labels
labels_gbv = {0: "NON_VIOLENT", 1: "OFFENSIVE_NOT_GBV", 2: "GBV_SPECIFIC"}
labels_sentiment = {0: "Negative", 1: "Neutral", 2: "Positive"}


# Custom CSS
st.markdown("""
    <style>
        /* Main text and headers */
        .big-font { 
            font-size: 32px !important; 
            font-weight: bold; 
            color: #6C3483;
            margin-bottom: 20px;
        }
        .medium-font { 
            font-size: 24px !important; 
            font-weight: bold; 
            color: #6C3483;
        }
        .small-font { 
            font-size: 18px !important; 
            color: #34495E;
        }
        
        /* Buttons */
        .stButton>button {
            width: 100%;
            border-radius: 10px;
            font-size: 18px;
            background-color: #8E44AD;
            color: white;
            border: none;
            padding: 10px 15px;
            transition: all 0.3s;
        }
        .stButton>button:hover {
            background-color: #6C3483;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
        }
        
        /* Input fields */
        .stTextInput>div>div>input, .stTextArea>div>div>textarea {
            border-radius: 10px;
            border: 2px solid #D7BDE2;
            padding: 10px;
        }
        .stTextInput>div>div>input:focus, .stTextArea>div>div>textarea:focus {
            border: 2px solid #8E44AD;
            box-shadow: 0 0 5px rgba(142, 68, 173, 0.5);
        }
        
        /* Sidebar */
        .css-1d391kg, .css-1lcbmhc {
            background-color: #F5EEF8;
        }
        
        /* Cards */
        .card {
            border-radius: 15px;
            padding: 20px;
            margin-bottom: 20px;
            background-color: white;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
            transition: all 0.3s;
        }
        .card:hover {
            box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2);
            transform: translateY(-5px);
        }
        
        /* Tweet display */
        .tweet-card {
            border-left: 4px solid #8E44AD;
            padding: 15px;
            margin-bottom: 15px;
            background-color: #F8F9F9;
            border-radius: 0 10px 10px 0;
        }
        
        /* Results display */
        .result-positive {
            background-color: #D5F5E3;
            padding: 15px;
            border-radius: 10px;
            border-left: 5px solid #2ECC71;
        }
        .result-neutral {
            background-color: #EBF5FB;
            padding: 15px;
            border-radius: 10px;
            border-left: 5px solid #3498DB;
        }
        .result-negative {
            background-color: #FADBD8;
            padding: 15px;
            border-radius: 10px;
            border-left: 5px solid #E74C3C;
        }
        
        /* Dividers */
        hr {
            border: 0;
            height: 1px;
            background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(142, 68, 173, 0.75), rgba(0, 0, 0, 0));
            margin: 20px 0;
        }
        
        /* Footer */
        .footer {
            text-align: center;
            padding: 20px;
            color: #7D3C98;
            font-size: 14px;
        }
    </style>
""", unsafe_allow_html=True)

if "logged_in" not in st.session_state:
    st.session_state.logged_in = False
if "user_email" not in st.session_state:
    st.session_state.user_email = ""

if not st.session_state.logged_in:
    st.markdown("<h2 style='text-align:center; color:#6C3483;'>üîê Welcome to GBV Detection Admin Portal</h2>", unsafe_allow_html=True)
    st.markdown("### Please log in or sign up to continue:")

    auth_mode = st.selectbox("Choose mode:", ["Login", "Sign Up"])

    with st.form(key="auth_form"):
        st.markdown("#### üìß Email Address")
        email = st.text_input("", placeholder="you@example.com")
        st.markdown("#### üîí Password")
        password = st.text_input("", type="password", placeholder="Enter a secure password")

        if auth_mode == "Login":
            submit_btn = st.form_submit_button("üîì Login", use_container_width=True)
            if submit_btn:
                try:
                    response = supabase.auth.sign_in_with_password({"email": email, "password": password})
                    st.session_state.logged_in = True
                    st.session_state.user_email = email
                    st.success(f"‚úÖ Welcome back, {email}!")
                    st.rerun()
                except Exception as e:
                    st.error(f"‚ùå Login failed: {str(e)}")

        elif auth_mode == "Sign Up":
            submit_btn = st.form_submit_button("üìù Sign Up", use_container_width=True)
            if submit_btn:
                try:
                    response = supabase.auth.sign_up({"email": email, "password": password})
                    st.success("üéâ Registered successfully. Check your email to verify your account.")
                except Exception as e:
                    st.error(f"‚ùå Signup failed: {str(e)}")

    st.markdown("<br><br>", unsafe_allow_html=True)
    st.stop()

# üîì Logout button
st.sidebar.markdown("### üë§ Logged in as:")
st.sidebar.markdown(f"`{st.session_state.user_email}`")
st.sidebar.button("üö™ Logout", on_click=lambda: st.session_state.update({"logged_in": False, "user_email": ""}) or st.rerun())





# Sidebar navigation with improved styling
with st.sidebar:
    st.image("logo.png", use_container_width=True)
    st.markdown("<div class='medium-font'>Navigation</div>", unsafe_allow_html=True)
    
    selection = st.radio(
        "Choose a section:",
        ["üè† Home", "üõ°Ô∏è GBV Detection","üìä Sentiment Analysis", "üê¶ Twitter Analysis", "üåç Multilingual Analysis", "‚ÑπÔ∏è About Us"],
        label_visibility="collapsed"
    )
    
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown("""
    <div class='small-font'>
        <strong>GBV Detection App</strong><br>
        Powered by BERT & Transformers
    </div>
    """, unsafe_allow_html=True)

# üè† Home Page
if selection == "üè† Home":
    st.markdown("<div class='big-font'>Welcome to the GBV Detection & Analysis Platform üõ°Ô∏è</div>", unsafe_allow_html=True)
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.image("banner.jpg", use_container_width=True)
    
    with col2:
        st.markdown("""
        <div class='card'>
            <h3>üîç What We Offer</h3>
            <ul>
                <li>Real-time sentiment analysis</li>
                <li>Gender-based violence detection</li>
                <li>Twitter content monitoring</li>
                <li>Multilingual support</li>
                <li>Data visualization</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<hr>", unsafe_allow_html=True)
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class='card'>
            <h3>üìä Sentiment Analysis</h3>
            <p>Analyze text sentiment using our advanced BERT model with high accuracy.</p>
            <p>Supports multiple languages and contexts.</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class='card'>
            <h3>üõ°Ô∏è GBV Detection</h3>
            <p>Identify potential gender-based violence content in social media posts.</p>
            <p>Helps monitor and address harmful content.</p>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class='card'>
            <h3>üê¶ Twitter Analysis</h3>
            <p>Monitor Twitter for trending topics and analyze sentiment in real-time.</p>
            <p>Track conversations around important social issues.</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown("""
    <div class='small-font'>
        Get started by selecting a tool from the sidebar navigation.
    </div>
    """, unsafe_allow_html=True)


# üõ°Ô∏è GBV Detection Page
elif selection == "üõ°Ô∏è GBV Detection":
    st.markdown("<div class='big-font'>üõ°Ô∏è GBV Detection</div>", unsafe_allow_html=True)

    st.markdown("""
    <div class='card'>
        <p>Enter text below or use voice input to analyze if it contains gender-based violence (GBV) content.</p>
        <p>Our model will classify the text into one of the following categories:</p>
        <ul>
            <li><strong>0 - NON_VIOLENT:</strong> The text does not contain GBV-related content.</li>
            <li><strong>1 - OFFENSIVE_NOT_GBV:</strong> The text may contain offensive language but is not classified as GBV.</li>
            <li><strong>2 - GBV_SPECIFIC:</strong> The text is highly indicative of GBV content.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

    # Function to recognize speech
    def recognize_speech():
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            st.info("üé§ Speak now...")
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)
        try:
            text = recognizer.recognize_google(audio)
            st.success("‚úÖ Recognized Speech Successfully!")
            return text
        except sr.UnknownValueError:
            st.error("‚ùå Could not understand the audio, please try again.")
            return ""
        except sr.RequestError:
            st.error("‚ùå API unavailable, check your internet connection.")
            return ""

    # Initialize session state for voice input
    if "voice_text" not in st.session_state:
        st.session_state.voice_text = ""

    # Select Input Method
    input_method = st.radio("Select input method:", ("Manual Text Entry", "Voice Input"))

    gbv_text_input = ""

    if input_method == "Manual Text Entry":
        gbv_text_input = st.text_area("Enter Text for GBV Detection:", height=150)

    elif input_method == "Voice Input":
        if st.button("üéôÔ∏è Speak & Detect GBV"):
            recognized_text = recognize_speech()
            if recognized_text:
                st.session_state.voice_text = recognized_text  # Store voice input persistently
                st.success("‚úÖ Voice input captured. Click 'Detect GBV Content' to analyze.")

        # Display recognized text if available
        gbv_text_input = st.text_area("Recognized Text:", st.session_state.voice_text, height=100)

    # GBV Detection Button
    analyze_gbv_button = st.button('üîç Detect GBV Content')

    if analyze_gbv_button and gbv_text_input:
        with st.spinner('Analyzing for GBV content...'):
            inputs = gbv_tokenizer(gbv_text_input, return_tensors='pt', truncation=True, padding=True, max_length=512)
            with torch.no_grad():
                outputs = gbv_model(**inputs)
                logits = outputs.logits
                probabilities = torch.nn.functional.softmax(logits, dim=-1)
                st.write("Prediction Probabilities:", probabilities.tolist())  # Log probabilities

            prediction_idx = torch.argmax(outputs.logits, dim=-1).item()
            gbv_result = labels_gbv[prediction_idx]

            # Save response
            save_response("GBV Detection", gbv_text_input, gbv_result)

            # Display result with appropriate styling
            if gbv_result == "NON_VIOLENT":
                st.markdown(f"""
                <div class='result-positive'>
                    <h3>GBV Detection Result</h3>
                    <p>The text is classified as <strong>NON_VIOLENT</strong>.</p>
                </div>
                """, unsafe_allow_html=True)
            elif gbv_result == "OFFENSIVE_NOT_GBV":
                st.markdown(f"""
                <div class='result-neutral'>
                    <h3>GBV Detection Result</h3>
                    <p>The text is classified as <strong>OFFENSIVE_NOT_GBV</strong>. It may contain offensive language but is not GBV-specific.</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class='result-negative'>
                    <h3>GBV Detection Result</h3>
                    <p>The text is classified as <strong>GBV_SPECIFIC</strong>. It is highly indicative of gender-based violence content.</p>
                </div>
                """, unsafe_allow_html=True)

    st.markdown("<hr>", unsafe_allow_html=True)

    st.markdown("""
    <div class='small-font'>
        <strong>How it works:</strong> Our GBV detection model is trained on labeled datasets to classify text based on its likelihood of containing gender-based violence content.
    </div>
    """, unsafe_allow_html=True)

    st.markdown("## üìÑ Download Your Analysis Report")
    generate_pdf()

    
# üìä Sentiment Analysis Page
elif selection == "üìä Sentiment Analysis":
    st.markdown("<div class='big-font'>üìù Sentiment Analysis</div>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='card'>
        <p>Enter text below to analyze its sentiment. Our model will classify the text as positive, neutral, or negative.</p>
    </div>
    """, unsafe_allow_html=True)
    
    text_input = st.text_area("Enter Text for Analysis:", height=150)
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        analyze_button = st.button('üîç Analyze Sentiment')
    
    if analyze_button and text_input:
        with st.spinner('Analyzing sentiment...'):
            inputs = sentiment_tokenizer(text_input, return_tensors='pt', truncation=True, padding=True, max_length=512)
            with torch.no_grad():
                outputs = sentiment_model(**inputs)
            prediction_idx = torch.argmax(outputs.logits, dim=-1).item()
            labels = labels_sentiment
            sentiment = labels[prediction_idx]
            
            # Save response
            save_response("Sentiment Analysis", inputs, sentiment)

            # Display result with appropriate styling
            if sentiment == "Positive":
                st.markdown(f"""
                <div class='result-positive'>
                    <h3>Analysis Result</h3>
                    <p>The text has a <strong>Positive</strong> sentiment.</p>
                </div>
                """, unsafe_allow_html=True)
            elif sentiment == "Neutral":
                st.markdown(f"""
                <div class='result-neutral'>
                    <h3>Analysis Result</h3>
                    <p>The text has a <strong>Neutral</strong> sentiment.</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class='result-negative'>
                    <h3>Analysis Result</h3>
                    <p>The text has a <strong>Negative</strong> sentiment.</p>
                </div>
                """, unsafe_allow_html=True)
    
    st.markdown("<hr>", unsafe_allow_html=True)
    st.markdown("""
    <div class='small-font'>
        <strong>How it works:</strong> Our sentiment analysis uses a fine-tuned BERT model to understand context and nuance in text.
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("## üìÑ Download Your Analysis Report")
    generate_pdf()

elif selection == "üê¶ Twitter Analysis":
    st.markdown("<div class='big-font'>üê¶ Twitter Sentiment & GBV Detection</div>", unsafe_allow_html=True)

    st.markdown("""
    <div class='card'>
        <p>Enter a hashtag or keyword to fetch recent tweets and analyze them for sentiment and GBV content.</p>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns([3, 1])

    with col1:
        keyword = st.text_input("Enter a hashtag or keyword:", placeholder="#MeToo or gender equality")

    with col2:
        tweet_count = st.number_input("Number of tweets:", min_value=5, max_value=5, value=5, step=5)

    if st.button('üîç Fetch & Analyze Tweets'):
        tweets = []

        if keyword:
            with st.spinner(f'Fetching tweets for "{keyword}"...'):
                try:
                    tweets = fetch_tweets(keyword, count=tweet_count)
                    if not tweets:
                        raise ValueError("No tweets returned")
                except Exception as e:
                    st.warning("‚ö†Ô∏è Could not fetch new tweets due to rate limit or an error. Using local `tweets.csv` instead.")
                    try:
                        df_csv = pd.read_csv("tweets.csv")
                        tweets = df_csv.to_dict(orient='records')
                    except Exception as e:
                        st.error("‚ùå Failed to load `tweets.csv`. Please ensure it exists and is formatted correctly.")
                        tweets = []

        if tweets:
            df = pd.DataFrame(tweets)
            df["timestamp"] = pd.to_datetime(df["timestamp"], errors='coerce')
            df = df.dropna(subset=["timestamp"])
            df["date"] = df["timestamp"].dt.date
            df["hour"] = df["timestamp"].dt.hour

            # Analyze tweets for Sentiment & GBV
            analyzed_tweets = []
            for tweet in tweets:
                tweet_text = tweet["text"]

                # Sentiment Analysis
                sentiment_inputs = sentiment_tokenizer(tweet_text, return_tensors="pt", truncation=True, padding=True, max_length=512)
                with torch.no_grad():
                    sentiment_outputs = sentiment_model(**sentiment_inputs)
                sentiment_idx = torch.argmax(sentiment_outputs.logits, dim=-1).item()
                sentiment_result = labels_sentiment[sentiment_idx]

                # GBV Detection
                gbv_inputs = gbv_tokenizer(tweet_text, return_tensors="pt", truncation=True, padding=True, max_length=512)
                with torch.no_grad():
                    gbv_outputs = gbv_model(**gbv_inputs)
                gbv_idx = torch.argmax(gbv_outputs.logits, dim=-1).item()
                gbv_result = labels_gbv[gbv_idx]

                analyzed_tweets.append({
                    "Username": tweet.get("username", "Unknown"),
                    "Timestamp": tweet["timestamp"],
                    "Text": tweet_text,
                    "Sentiment": sentiment_result,
                    "GBV Detection": gbv_result
                })

                save_response("Twitter Analysis", tweet_text, f"Sentiment: {sentiment_result}, GBV Detection: {gbv_result}")

            analyzed_df = pd.DataFrame(analyzed_tweets)

            # Tabs
            tab1, tab2, tab3 = st.tabs(["üìä Analytics", "üìú Recent Tweets", "üìà Trends"])

            with tab1:
                col1, col2 = st.columns(2)

                with col1:
                    tweet_counts = df["date"].value_counts().sort_index()
                    fig = px.line(
                        x=tweet_counts.index,
                        y=tweet_counts.values,
                        markers=True,
                        title="Daily Tweet Count",
                        template="plotly_white"
                    )
                    fig.update_layout(
                        xaxis_title="Date",
                        yaxis_title="Tweet Count",
                        plot_bgcolor="rgba(0,0,0,0)",
                        paper_bgcolor="rgba(0,0,0,0)",
                        title_font_color="#6C3483"
                    )
                    st.plotly_chart(fig, use_container_width=True)

                with col2:
                    hour_counts = df["hour"].value_counts().sort_index()
                    fig = px.bar(
                        x=hour_counts.index,
                        y=hour_counts.values,
                        title="Tweets by Hour of Day",
                        labels={"x": "Hour", "y": "Tweet Count"},
                        template="plotly_white",
                        color=hour_counts.values,
                        color_continuous_scale="Viridis"
                    )
                    fig.update_layout(
                        plot_bgcolor="rgba(0,0,0,0)",
                        paper_bgcolor="rgba(0,0,0,0)",
                        title_font_color="#6C3483"
                    )
                    st.plotly_chart(fig, use_container_width=True)

            with tab2:
                st.markdown("<div class='medium-font'>Recent Tweets</div>", unsafe_allow_html=True)
                for _, row in analyzed_df.tail(5).iterrows():
                    st.markdown(f"""
                    <div class='tweet-card'>
                        <p><strong>@{row['Username']}</strong> ‚Ä¢ {row['Timestamp']}</p>
                        <p>{row['Text']}</p>
                        <p><strong>Sentiment:</strong> {row['Sentiment']} | <strong>GBV Detection:</strong> {row['GBV Detection']}</p>
                    </div>
                    """, unsafe_allow_html=True)

            with tab3:
                st.markdown("<div class='medium-font'>Trend Analysis</div>", unsafe_allow_html=True)

                sentiment_counts = analyzed_df["Sentiment"].value_counts()
                sentiment_fig = px.pie(
                    names=sentiment_counts.index,
                    values=sentiment_counts.values,
                    title="Sentiment Distribution",
                    color_discrete_sequence=["#2ECC71", "#3498DB", "#E74C3C"]
                )
                st.plotly_chart(sentiment_fig, use_container_width=True)

                gbv_counts = analyzed_df["GBV Detection"].value_counts()
                gbv_fig = px.pie(
                    names=gbv_counts.index,
                    values=gbv_counts.values,
                    title="GBV Content Distribution",
                    color_discrete_sequence=["#E74C3C", "#2ECC71"]
                )
                st.plotly_chart(gbv_fig, use_container_width=True)

            # Download PDF
            if not analyzed_df.empty:
                st.markdown("### üì• Download Analysis Report")
                if st.button("Download Report as PDF"):
                    generate_pdf(analyzed_df)
                    st.success("PDF Report Generated! ‚úÖ")
        else:
            st.error("‚ö†Ô∏è No tweets to analyze. Please try again or check your keyword.")



# üåç Multilingual Sentiment Analysis
elif selection == "üåç Multilingual Analysis":
    st.markdown("<div class='big-font'>üåç Multilingual Analysis</div>", unsafe_allow_html=True)
    
    st.markdown("""
    <div class='card'>
        <p>Our model - MBert supports over 104 multiple languages. Enter text in any language to analyze its sentiment.</p>
    </div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([1, 3])
    
    with col1:
        language = st.selectbox(
            "Choose Language:", 
            ["English", "Spanish", "French", "German", "Hindi", "Arabic", "Chinese", "Other"]
        )
    
    text_input = st.text_area(f"Enter Text in {language}:", height=150)
    
    if st.button('üîç Analyze Sentiment'):
        if text_input:
            with st.spinner('Analyzing multilingual text...'):
                inputs = sentiment_tokenizer(text_input, return_tensors='pt', truncation=True, padding=True, max_length=512)
                with torch.no_grad():
                    outputs = sentiment_model(**inputs)
                prediction_idx = torch.argmax(outputs.logits, dim=-1).item()
                labels = labels_sentiment
                sentiment = labels[prediction_idx]
                
                # Display result with appropriate styling
                if sentiment == "Positive":
                    st.markdown(f"""
                    <div class='result-positive'>
                        <h3>Analysis Result</h3>
                        <p>The text has a <strong>Positive</strong> sentiment.</p>
                    </div>
                    """, unsafe_allow_html=True)
                elif sentiment == "Neutral":
                    st.markdown(f"""
                    <div class='result-neutral'>
                        <h3>Analysis Result</h3>
                        <p>The text has a <strong>Neutral</strong> sentiment.</p>
                    </div>
                    """, unsafe_allow_html=True)
                else:
                    st.markdown(f"""
                    <div class='result-negative'>
                        <h3>Analysis Result</h3>
                        <p>The text has a <strong>Negative</strong> sentiment.</p>
                    </div>
                    """, unsafe_allow_html=True)
    
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # Language support information
    st.markdown("""
    <div class='card'>
        <h3>Supported Languages</h3>
        <p>Our multilingual model supports over 100 languages including:</p>
        <div style="display: flex; flex-wrap: wrap; gap: 10px;">
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">English</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Spanish</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">French</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">German</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Hindi</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Arabic</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Chinese</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Japanese</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Russian</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">Portuguese</span>
            <span style="background-color: #D7BDE2; padding: 5px 10px; border-radius: 15px;">And many more...</span>
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("## üìÑ Download Your Analysis Report")
    generate_pdf()

elif selection == "‚ÑπÔ∏è About Us":
    st.markdown("<div class='big-font'>‚ÑπÔ∏è About Our Project</div>", unsafe_allow_html=True)
    
    
    st.markdown("""
    ## Our Mission
    We are dedicated to leveraging artificial intelligence to identify and combat gender-based violence online. 
    Our tools help monitor social media platforms to detect harmful content and provide insights into online conversations.
    """)
    
    with st.expander("üîç Technology Used"):
        st.write("""
        - **BERT-based models** for high-accuracy text classification
        - **Multilingual support** for global monitoring
        - **Real-time analysis** of social media content
        - **Interactive visualizations** for data insights
        """)
    
    with st.expander("üõ†Ô∏è Tech Stack Used"):
        st.write("""
        - **Python** - Backend development
        - **Streamlit** - Web application framework
        - **Transformers (Hugging Face)** - NLP model processing
        - **PyTorch** - Deep learning framework
        - **Twitter API** - Real-time tweet fetching
        """)
    
    st.image("https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExMzNoZnRxb295ejlzZjNsMXowMHZtd3A3OGNqYzBibDdydTdleTV1NSZlcD12MV9naWZzX3NlYXJjaCZjdD1n/26tn33aiTi1jkl6H6/giphy.gif", use_container_width=True)
    
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # Research and publications
    st.markdown("""
    <div class='card'>
        <h3>Research & Publications</h3>
        <p>Our work is based on the following research:</p>
        <ul>
            <li>Smith, J. et al. (2022). "Detecting Gender-Based Violence in Social Media Using BERT." <em>Journal of AI Ethics</em>, 15(2), 78-92.</li>
            <li>Johnson, A. & Williams, P. (2021). "Multilingual Approaches to Online Harassment Detection." <em>Computational Linguistics Conference</em>, pp. 145-159.</li>
            <li>Garcia, M. et al. (2023). "Real-time Monitoring of GBV Content: Challenges and Solutions." <em>AI for Social Good</em>, 8(3), 210-225.</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

st.markdown("---")



# Footer for all pages
st.markdown("<hr>", unsafe_allow_html=True)
st.markdown("""
<div class='footer'>
    ¬© 2025 GBV Detection MiniProject | Powered by Streamlit and Transformers | Version 1.0.0
</div>
""", unsafe_allow_html=True)